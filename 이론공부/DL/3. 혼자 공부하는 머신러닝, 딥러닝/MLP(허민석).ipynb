{"cells":[{"cell_type":"markdown","metadata":{"id":"DIUEvt7tYvKz"},"source":["# MLP (MNIST, Tensorflow)\n","In this tutorial, we will use MNIST data to practice Multi Layer Perceptron with Tensorflow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyeoNQPgYvK_"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from IPython.display import Image"]},{"cell_type":"markdown","metadata":{"id":"8jpt1vlpYvLF"},"source":["# MLP Architecture\n","here is the overview of MLP architecture we will implement with Tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bVx325ynYvLG","outputId":"48d428b2-9c38-4231-a687-cd13acae1998"},"outputs":[{"data":{"text/html":["<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\" width=\"500\" height=\"250\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\", width=500, height=250)"]},{"cell_type":"markdown","source":["- 인풋레이어1개, 히든레이어가 2개, 아웃풋 레이어 1개이고 레이어 별로 노드수가 다름\n","  - 노드별로 bias 1개씩 있음\n","  - 일부 레이어에 일부 노드를 사용하지 않는 'drop out' 적용가능 \n","- 총 계산된 레이어가 precition. 이거를 activation(prediction)\n","  - 이걸 레이블 값과 비교함.\n","  - 비교하면서 수정하는것을 '오차역전파'\n","    - 수정하는방법이 '경사하강법'\n","    - local 이슈 피하기위해 'optimizer'\n","- input data : (70000,28,28 : input layer랑 다른거임) \n","  - 28 * 28 -> 784로 resshape\n","- label : 10 \n","  - 원핫인코딩 적용 "],"metadata":{"id":"fTV5rgBUYwl9"}},{"cell_type":"markdown","metadata":{"id":"Wyj6EQ-4YvLJ"},"source":["# Collect MNIST Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CoJFNdj5YvLK"},"outputs":[],"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqUqNl1KYvLL","outputId":"8cf53ed4-21df-4192-fc73-64bd367d0ba1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(60000, 28, 28)\n","(10000, 28, 28)\n"]}],"source":["print(x_train.shape)\n","print(x_test.shape)"]},{"cell_type":"markdown","source":["- 7만개중 검증 데이터에 1만개할당\n","- 각 데이터가 28x28픽셀로 이루어짐"],"metadata":{"id":"McjVQovsZQGY"}},{"cell_type":"markdown","metadata":{"id":"oXywGjtdYvLN"},"source":["train data has **60000** samples  \n","test data has **10000** samples   \n","every data is **28 * 28** pixels  \n","\n","below image shows 28*28 pixel image sample for hand written number '0' from MNIST data.  \n","MNIST is gray scale image [0 to 255] for hand written number."]},{"cell_type":"markdown","metadata":{"id":"vU-SiVbqYvLO"},"source":["![0 from MNIST](https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/mnist_sample.png)"]},{"cell_type":"markdown","metadata":{"id":"UQOHnKVTYvLQ"},"source":["# Split train data into train and validation data\n","Validation during training gives advantages below,  \n","1) check if train goes well based on validation score  \n","2) apply **early stopping** when validation score doesn't improve while train score goes up (overcome **overfitting**)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a98tnyyDYvLR"},"outputs":[],"source":["x_val  = x_train[50000:60000]\n","x_train = x_train[0:50000]\n","y_val  = y_train[50000:60000]\n","y_train = y_train[0:50000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qfYX4i9YvLS","outputId":"606675f9-0080-415b-f164-47ece542aaf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["train data has 50000 samples\n","every train data is 28 * 28 image\n"]}],"source":["print(\"train data has \" + str(x_train.shape[0]) + \" samples\")\n","print(\"every train data is \" + str(x_train.shape[1]) \n","      + \" * \" + str(x_train.shape[2]) + \" image\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27AOHvLhYvLT","outputId":"19fd8944-7c50-4dc1-d04e-8bca269cbddb"},"outputs":[{"name":"stdout","output_type":"stream","text":["validation data has 10000 samples\n","every train data is 28 * 28 image\n"]}],"source":["print(\"validation data has \" + str(x_val.shape[0]) + \" samples\")\n","print(\"every train data is \" + str(x_val.shape[1]) \n","      + \" * \" + str(x_train.shape[2]) + \" image\")"]},{"cell_type":"markdown","metadata":{"id":"f3whdPnQYvLU"},"source":["28 * 28 pixels has gray scale value from **0** to **255**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Fg9J3mSYvLU","outputId":"ad9c393f-7705-43a7-9e0d-159834ba35ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["[  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n","   0   0   0   0   0   0   0   0   0   0]\n"]}],"source":["# sample to show gray scale values\n","print(x_train[0][8])"]},{"cell_type":"markdown","metadata":{"id":"bpeqvTrhYvLV"},"source":["each train data has its label **0** to **9**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1rqAiSEzYvLW","outputId":"4c797be4-64ab-4d18-9da0-3d69cce39807"},"outputs":[{"name":"stdout","output_type":"stream","text":["[5 0 4 1 9 2 1 3 1]\n"]}],"source":["# sample to show labels for first train data to 10th train data\n","print(y_train[0:9])"]},{"cell_type":"markdown","metadata":{"id":"6IxgYePYYvLX"},"source":["test data has **10000** samples  \n","every test data is **28 * 28** image  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ofIhrN-GYvLX","outputId":"ba300b43-d7cf-4488-d1dd-8bb98b7b0d84"},"outputs":[{"name":"stdout","output_type":"stream","text":["test data has 10000 samples\n","every test data is 28 * 28 image\n"]}],"source":["print(\"test data has \" + str(x_test.shape[0]) + \" samples\")\n","print(\"every test data is \" + str(x_test.shape[1]) \n","      + \" * \" + str(x_test.shape[2]) + \" image\")"]},{"cell_type":"markdown","metadata":{"id":"ywmZJmZ6YvLY"},"source":["# Reshape\n","In order to fully connect all pixels to hidden layer,  \n","we will reshape (28, 28) into (28x28,1) shape.  \n","It means we flatten row x column shape to an array having 28x28 (784) items."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GSc2t1zYvLZ","outputId":"df0ab428-1a78-4dd0-ff8b-cd342aed4d2e"},"outputs":[{"data":{"text/html":["<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/reshape_mnist.png\" width=\"500\" height=\"250\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/reshape_mnist.png\", width=500, height=250)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJFC5P-0YvLa","outputId":"fbc762d4-1648-4f4b-dd08-9a425c706130"},"outputs":[{"name":"stdout","output_type":"stream","text":["(50000, 784)\n","(10000, 784)\n"]}],"source":["x_train = x_train.reshape(50000, 784)\n","x_val = x_val.reshape(10000, 784)\n","x_test = x_test.reshape(10000, 784)\n","\n","print(x_train.shape)\n","print(x_test.shape)"]},{"cell_type":"markdown","source":["- 28*28을 784로 reshape해줌"],"metadata":{"id":"6Ab-AVshaBBS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZotB8GUVYvLb","outputId":"4dc1d1f4-32ef-4326-d0c6-b4222357f79d"},"outputs":[{"data":{"text/plain":["array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n","       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n","       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n","       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n","       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n","       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n","       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n","       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n","       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n","       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n","       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n","       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n","       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0], dtype=uint8)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["x_train[0]"]},{"cell_type":"markdown","metadata":{"id":"Y3qdzW5BYvLc"},"source":["# Normalize data\n","normalization usually helps faster learning speed, better performance  \n","by reducing variance and giving same range to all input features.  \n","since MNIST data set all input has 0 to 255, normalization only helps reducing variances.  \n","it turned out normalization is better than standardization for MNIST data with my MLP architeture,    \n","I believe this is because relu handles 0 differently on both feed forward and back propagation.  \n","handling 0 differently is important for MNIST, since 1-255 means there is some hand written,  \n","while 0 means no hand written on that pixel."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JMIBWuQeYvLd"},"outputs":[],"source":["x_train = x_train.astype('float32')\n","x_val = x_val.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","gray_scale = 255\n","x_train /= gray_scale\n","x_val /= gray_scale\n","x_test /= gray_scale"]},{"cell_type":"markdown","source":["- 255로 나눠주는게 곧 정규화 "],"metadata":{"id":"cEZqm2gIaGEs"}},{"cell_type":"markdown","metadata":{"id":"GrMfYebHYvLd"},"source":["# label to one hot encoding value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEPA9titYvLe"},"outputs":[],"source":["num_classes = 10\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0jANLIumYvLe","outputId":"4927634c-fe2d-4666-839d-114b488f072e"},"outputs":[{"data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 1., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 1., 0.]])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["y_train"]},{"cell_type":"markdown","source":["- y값 (0~9)를 one hot encoding해준다 \n","  - 숫자간의 관계가 없으니까 인코딩 이렇게 해주는거지\n","- one hot\n","  - 1 : 1 0 0 0 0 0 0 0 0 0\n","  - 2: 0 1 0 0 0 0 0 0 0 0\n","  - 3: 0 0 1 0 0 0 0 0 0 0"],"metadata":{"id":"Mg6XSbMZaLKp"}},{"cell_type":"markdown","metadata":{"id":"UMcLm-gqYvLf"},"source":["# Tensorflow MLP Graph\n","Let's implement the MLP graph with Tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ic-drLIrYvLf","outputId":"881c7dea-6d1d-4da3-e717-ba273772e233"},"outputs":[{"data":{"text/html":["<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\" width=\"500\" height=\"250\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\", width=500, height=250)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivG5uD38YvLg"},"outputs":[],"source":["x = tf.placeholder(tf.float32, [None, 784]) # None만큼의 샘플을 받고 784개의 칼럼을 가진 x라는 의미\n","y = tf.placeholder(tf.float32, [None, 10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ec9epMUfYvLg"},"outputs":[],"source":["def mlp(x):\n","    # hidden layer1\n","    w1 = tf.Variable(tf.random_uniform([784,256])) # 784개의 인풋을 받고 256개의 노드로 처리한다\n","    b1 = tf.Variable(tf.zeros([256])) ## bias는 node 수 마다 있는거다\n","    h1 = tf.nn.relu(tf.matmul(x, w1) + b1) ## relu는 활성화 함수\n","    # hidden layer2\n","    w2 = tf.Variable(tf.random_uniform([256,128])) # 256개의 인풋을 받고 128개의 노드로 처리한다\n","    b2 = tf.Variable(tf.zeros([128]))\n","    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n","    # output layer\n","    w3 = tf.Variable(tf.random_uniform([128,10]))\n","    b3 = tf.Variable(tf.zeros([10]))\n","    logits= tf.matmul(h2, w3) + b3\n","    \n","    return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_hPLySlYvLh"},"outputs":[],"source":["logits = mlp(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjkb4StRYvLh"},"outputs":[],"source":["loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n","    logits=logits, labels=y)) ## 손실함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2xGDalLYvLh"},"outputs":[],"source":["train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op) ## optimizer"]},{"cell_type":"markdown","source":["실제 학습 돌리는 코드 (아래)"],"metadata":{"id":"vS-ykYp1az_5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"17wKoP7oYvLi","outputId":"55ff4abf-2639-4525-c1b7-f6283e0f1646"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 0, validation accuracy: 0.1064, loss: 9479.23924316406\n","epoch: 1, validation accuracy: 0.7404, loss: 487.9066563034058\n","epoch: 2, validation accuracy: 0.8683, loss: 20.24389074325562\n","epoch: 3, validation accuracy: 0.8761, loss: 11.892984285354613\n","epoch: 4, validation accuracy: 0.8858, loss: 9.276838760375973\n","epoch: 5, validation accuracy: 0.8785, loss: 8.25918293952942\n","epoch: 6, validation accuracy: 0.8832, loss: 7.402374687194823\n","epoch: 7, validation accuracy: 0.906, loss: 6.622725062370303\n","epoch: 8, validation accuracy: 0.9034, loss: 5.537717547416686\n","epoch: 9, validation accuracy: 0.8971, loss: 4.807866144180299\n","epoch: 10, validation accuracy: 0.8396, loss: 7.349521398544313\n","epoch: 11, validation accuracy: 0.9066, loss: 6.607095966339113\n","epoch: 12, validation accuracy: 0.8217, loss: 52.06143003463745\n","epoch: 13, validation accuracy: 0.8922, loss: 15.170511302948\n","epoch: 14, validation accuracy: 0.9016, loss: 6.205790314674376\n","epoch: 15, validation accuracy: 0.9036, loss: 4.978821859359741\n","epoch: 16, validation accuracy: 0.9083, loss: 4.454537310600279\n","epoch: 17, validation accuracy: 0.9112, loss: 3.8163385868072504\n","epoch: 18, validation accuracy: 0.9137, loss: 3.665376300811767\n","epoch: 19, validation accuracy: 0.9171, loss: 3.8778756713867173\n","epoch: 20, validation accuracy: 0.9159, loss: 3.3953911519050597\n","epoch: 21, validation accuracy: 0.9175, loss: 3.1974300575256356\n","epoch: 22, validation accuracy: 0.8809, loss: 4.378022892475128\n","epoch: 23, validation accuracy: 0.8764, loss: 4.933798418045042\n","epoch: 24, validation accuracy: 0.912, loss: 4.379148626327513\n","epoch: 25, validation accuracy: 0.9154, loss: 3.86887104511261\n","epoch: 26, validation accuracy: 0.9196, loss: 3.1193934822082525\n","epoch: 27, validation accuracy: 0.9205, loss: 2.864556527137757\n","epoch: 28, validation accuracy: 0.9095, loss: 2.6170078659057614\n","epoch: 29, validation accuracy: 0.9123, loss: 2.499971570968628\n","[Test Accuracy] : 0.9089\n"]}],"source":["# initialize : 그냥 항상 필요한거라는데\n","init = tf.global_variables_initializer()\n","\n","# train hyperparameters\n","epoch_cnt = 30 # 총 30회 할건데\n","batch_size = 1000 # 5만개 데이터 중 1000개를 한 batch 사이즈로 -> 한 에포크당 50번의 iteration(batch)을 가진다\n","iteration = len(x_train) // batch_size\n","\n","# Start training\n","with tf.Session() as sess:\n","    # Run the initializer\n","    sess.run(init) # 변수 초기화 기능\n","    for epoch in range(epoch_cnt):\n","        avg_loss = 0.\n","        start = 0; end = batch_size\n","        \n","        for i in range(iteration):\n","            _, loss = sess.run([train_op, loss_op], \n","                               feed_dict={x: x_train[start: end], y: y_train[start: end]})\n","            start += batch_size; end += batch_size\n","            # Compute average loss\n","            avg_loss += loss / iteration\n","            \n","        # Validate model\n","        preds = tf.nn.softmax(logits)  # Apply softmax to logits\n","        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n","        # Calculate accuracy\n","        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n","        cur_val_acc = accuracy.eval({x: x_val, y: y_val})\n","        print(\"epoch: \"+str(epoch)+\", validation accuracy: \" \n","              + str(cur_val_acc) +', loss: '+str(avg_loss))\n","    \n","    # Test model\n","    preds = tf.nn.softmax(logits)  # Apply softmax to logits\n","    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n","    # Calculate accuracy\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n","    print(\"[Test Accuracy] :\", accuracy.eval({x: x_test, y: y_test}))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"MLP(허민석).ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}